name: Weekly Refactoring Audit

on:
  schedule:
    - cron: '0 8 * * 0'
  workflow_dispatch:

permissions:
  contents: read
  issues: write

jobs:
  audit-refactoring:
    runs-on: ubuntu-latest
    env:
      BASELINE_LARGE_FILES: 24
      BASELINE_TODOS: 4
      BASELINE_VULNS: 3
      BASELINE_DEAD_EXPORTS: 3
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Check for large files (over 500 lines)
        id: large-files
        run: |
          find src/ \( -name "*.ts" -o -name "*.tsx" \) -print0 | \
            xargs -0 wc -l 2>/dev/null | \
            sort -rn | \
            awk '$1 > 500 && $2 != "total" {print $0}' > /tmp/large-files.txt
          LARGE_COUNT=$(wc -l < /tmp/large-files.txt | tr -d ' ')
          echo "large_count=$LARGE_COUNT" >> $GITHUB_OUTPUT

      - name: Scan for TODO/HACK/FIXME comments
        id: todos
        run: |
          grep -rn "TODO\|HACK\|FIXME\|XXX" src/ --include="*.ts" --include="*.tsx" \
            > /tmp/todos.txt 2>/dev/null || true
          TODO_COUNT=$(wc -l < /tmp/todos.txt | tr -d ' ')
          echo "todo_count=$TODO_COUNT" >> $GITHUB_OUTPUT

      - name: Run npm audit
        id: npm-audit
        run: |
          npm audit --production --json 2>/dev/null > /tmp/npm-audit.json || true
          HIGH_COUNT=$(node -e "
            try {
              const d = JSON.parse(require('fs').readFileSync('/tmp/npm-audit.json', 'utf8'));
              const v = d.metadata && d.metadata.vulnerabilities;
              console.log(v ? (v.high || 0) : 0);
            } catch(e) { console.log(0); }
          ")
          echo "high_count=$HIGH_COUNT" >> $GITHUB_OUTPUT
          npm audit --production 2>/dev/null | tail -5 > /tmp/npm-audit-summary.txt || true

      - name: Scan for potential dead exports
        id: dead-exports
        run: |
          grep -rh "^export " src/config/ src/lib/ --include="*.ts" 2>/dev/null | \
            grep -oP "(?:const|function|class|type|interface|enum)\s+\K\w+" | \
            sort -u > /tmp/all-exports.txt

          DEAD_EXPORTS_LIST=""
          DEAD_COUNT=0

          while IFS= read -r name; do
            if [ -z "$name" ]; then continue; fi
            IMPORT_COUNT=$(grep -rw "$name" src/ --include="*.ts" --include="*.tsx" \
              2>/dev/null -l | wc -l | tr -d ' ')
            if [ "${IMPORT_COUNT}" -le 1 ]; then
              DEAD_EXPORTS_LIST="${DEAD_EXPORTS_LIST}\n- \`${name}\`"
              DEAD_COUNT=$((DEAD_COUNT + 1))
            fi
          done < /tmp/all-exports.txt

          echo "dead_count=$DEAD_COUNT" >> $GITHUB_OUTPUT
          printf "%b" "$DEAD_EXPORTS_LIST" > /tmp/dead-exports.txt

      - name: Determine if issue is needed
        id: should-create-issue
        run: |
          LARGE=$(( ${{ steps.large-files.outputs.large_count }} + 0 ))
          TODOS=$(( ${{ steps.todos.outputs.todo_count }} + 0 ))
          HIGH=$(( ${{ steps.npm-audit.outputs.high_count }} + 0 ))
          DEAD=$(( ${{ steps.dead-exports.outputs.dead_count }} + 0 ))

          NEEDS_ISSUE=false
          if [ "$LARGE" -gt "${{ env.BASELINE_LARGE_FILES }}" ] || \
             [ "$TODOS" -gt "${{ env.BASELINE_TODOS }}" ] || \
             [ "$HIGH" -gt "${{ env.BASELINE_VULNS }}" ] || \
             [ "$DEAD" -gt "${{ env.BASELINE_DEAD_EXPORTS }}" ]; then
            NEEDS_ISSUE=true
          fi

          echo "needs_issue=$NEEDS_ISSUE" >> $GITHUB_OUTPUT

      - name: Create refactoring issue
        if: steps.should-create-issue.outputs.needs_issue == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const date = new Date().toISOString().split('T')[0];

            const largeFilesContent = fs.readFileSync('/tmp/large-files.txt', 'utf8').trim();
            const todosContent = fs.readFileSync('/tmp/todos.txt', 'utf8').trim();
            const auditSummary = fs.readFileSync('/tmp/npm-audit-summary.txt', 'utf8').trim();
            const deadExports = fs.readFileSync('/tmp/dead-exports.txt', 'utf8').trim();

            const largeCount = ${{ steps.large-files.outputs.large_count }};
            const todoCount = ${{ steps.todos.outputs.todo_count }};
            const highCount = ${{ steps.npm-audit.outputs.high_count }};
            const deadCount = ${{ steps.dead-exports.outputs.dead_count }};

            const baselineL = ${{ env.BASELINE_LARGE_FILES }};
            const baselineT = ${{ env.BASELINE_TODOS }};
            const baselineV = ${{ env.BASELINE_VULNS }};
            const baselineD = ${{ env.BASELINE_DEAD_EXPORTS }};

            const flag = (current, baseline) =>
              current > baseline ? '\u26A0\uFE0F NEW (' + current + ' vs baseline ' + baseline + ')' :
                                   '\u2705 Baseline (' + current + ')';

            const lines = [
              '## \uD83D\uDD27 Weekly Refactoring Audit \u2014 ' + date,
              '',
              '> Metrics that exceed baselines are flagged with \u26A0\uFE0F NEW.',
              '> Baselines reflect the known state as of February 2026.',
              '',
              '---',
              '',
              '## \uD83D\uDCCF Large Files (>500 lines)',
              '',
              flag(largeCount, baselineL),
              '',
              largeFilesContent ? ('```\n' + largeFilesContent + '\n```') : '_None found_',
              '',
              '---',
              '',
              '## \uD83D\uDCDD TODO/HACK/FIXME Comments',
              '',
              flag(todoCount, baselineT),
              '',
              todosContent ? ('```\n' + todosContent + '\n```') : '_None found_',
              '',
              '---',
              '',
              '## \uD83D\uDD12 Dependency Vulnerabilities (high severity)',
              '',
              flag(highCount, baselineV),
              '',
              '```',
              auditSummary || 'Audit unavailable',
              '```',
              '',
              '---',
              '',
              '## \u267B\uFE0F Potential Dead Exports',
              '',
              '> \u26A0\uFE0F These may be false positives \u2014 verify before removing.',
              '> Dynamic imports, re-exports, and external consumers are not detected.',
              '',
              flag(deadCount, baselineD),
              '',
              deadExports || '_None found_',
              '',
              '---',
              '',
              '## \uD83D\uDD0D Claude Code Remediation Prompt',
              '',
              'Use this prompt to address the most actionable NEW findings:',
              '',
              '```',
              'Review the weekly refactoring audit findings for the Savvy Dashboard.',
              '',
              'Priority order:',
              '1. Any NEW high-severity npm vulnerabilities \u2014 check if fixable without breaking changes',
              '2. Any new TODO/HACK comments \u2014 review and either implement or create a ticket',
              '3. Files newly exceeding 500 lines \u2014 assess if extraction is practical',
              '4. Verify dead exports before removing \u2014 check for dynamic usage patterns',
              '',
              'Rules:',
              '- Read each flagged file before making changes',
              '- Do NOT modify source code without understanding the change impact',
              '- For npm vulnerabilities: prefer npm audit fix over npm audit fix --force',
              '```',
              '',
              '---',
              '_This issue was created automatically by the Weekly Refactoring Audit workflow._'
            ].join('\n');

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '\uD83D\uDD27 Weekly Refactoring Audit \u2014 ' + date,
              body: lines,
              labels: ['refactoring', 'automated-audit']
            });
